---
.title = "Home",
.date = @date("2020-07-06T00:00:00"),
.author = "jeroenflvr",
.layout = "index.shtml",
.draft = false,
---

># [Warning]($block.attrs('warning'))
>This DuckB Extension is a test.  
>To help me understand DuckDB and maybe use JSON APIs.
>
> -- Using [Zine](https://zine-ssg.io/)'s theme just because it's awesome and convenient. --

## What?
I'm discovering how DuckDB works internally. I've been using it mainly for ad hoc stuff with the excellent cli.
Also, I have a few use cases for accessing json data from api's.  Some are very simple, others are similar to MongoDB.

I could have used the already excellent [json](https://duckdb.org/docs/extensions/json) extension
with an external data fetcher, or even the [shellfs](https://community-extensions.duckdb.org/extensions/shellfs.html) 
extension with curl.  Actually, that's how i do it today, use curl and pipe into the read_json /dev/stdin source.
However, when I'm in the CLI, I want to stay there.  Especially when I'm running multiple consecutive queries for joins etc.

## Why this site?
I want to document for future self.  Also, there's this excellent *[at the boundary](https://blog.debug.sexy/)* blog. 
Started at about the same time I was looking into table functions and realizing there was no good documentation and examples (yet).

## Scalar functions
These return a single value. The [extension template](https://github.com/duckdb/extension-template) has the Quack example.

## Table functions
Obviously, these return tables.  Retrieve data, process schema and data types.
There are no good starters for this yet.  You can have a look at the parquet extension or the json extension, but they are a bit of a 
handful to get started with. 

Supports threaded execution.

## Anatomy of the table function

### Register the TableFunction
- bind
- init
- table function    
    - filer pushdown (where)
    - projection pushdown (columns)
    - pushdown complex filter
    - positional and named parameters
    - extension options: PRAGMA/SET
    - cardinality: keep track of progress (#rows)

![](/example_tf.png)


### Order of execution
1. bind

    Here, we have access to positional and named arguments.  
    This is where I get the schema from the extension's configuration or from a separate endpoint. Return a struct with whatever we want to pass further down the line.

2. init

    When projection_pushdown is enabled, we get the id of the columns from the SELECT statement. Return these.

3. execute table function

    Get the schema, column ids, filters, etc. 
    Order_by and limit are not part of any pushdown, however, they are accessible through the ResultModifier class.

    This is where we get the data from a json api (paged and threaded), parse and return.
    Cardinality manages progress.
